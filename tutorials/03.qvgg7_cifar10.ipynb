{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f4441533-4d5a-4c9e-8906-1df24bda96ec",
   "metadata": {},
   "source": [
    "## Tutorial 1. VGG7 on CIFAR10. \n",
    "\n",
    "\n",
    "In this tutorial, we will show \n",
    "\n",
    "- How to end-to-end train and compress a VGG7 model from scratch on CIFAR10 to get a pruned and quantized VGG7.\n",
    "- We apply both weight and activation quantization when training VGG7 model.\n",
    "- Using the following script, we are able to reach a 92.57% test accuracy with 0.41% relative bits of operation.\n",
    "<!-- - The compressed ResNet18 achives both **high performance** and **significant FLOPs and parameters reductions** than the full model. \n",
    "- The compressed ResNet18 **reduces about 92% parameters** to achieve **92.91% accuracy** only lower than the baseline by **0.11%**.\n",
    "- More detailed new HESSO optimizer setup. (Technical report regarding HESSO will be released on the early of 2024). -->"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8067c3a6-bf56-4c85-96fb-2d4da488680b",
   "metadata": {},
   "source": [
    "### Step 1. Create OTO instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2ce0399-51c7-4afc-b0f0-35bda3698825",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-14 00:02:47,924 - only_train_once.quantization.quant_model - INFO - Converted 8 layers to quantized versions\n",
      "c:\\Users\\xiaoy\\OneDrive\\Desktop\\Github Projects\\GETA\\geta\\tutorials\\..\\only_train_once\\quantization\\quant_layers.py:334: TracerWarning: torch.tensor results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.\n",
      "  weight_clip_val = torch.tensor(self.weight_clip_val, device=weight.device)\n",
      "c:\\Users\\xiaoy\\OneDrive\\Desktop\\Github Projects\\GETA\\geta\\tutorials\\..\\only_train_once\\quantization\\quant_layers.py:335: TracerWarning: torch.tensor results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.\n",
      "  q_s = torch.tensor(0.0, device=weight.device)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OTO graph constructor\n",
      "graph build\n",
      "NodePattern mul None\n",
      "NodePattern transpose None\n",
      "NodePattern matmul None\n",
      "Post-processing of graph completed.\n",
      "Graph has 28 nodes and 27 edges.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "from only_train_once.quantization.quant_model import model_to_quantize_model\n",
    "from only_train_once.quantization.quant_layers import QuantizationMode\n",
    "from sanity_check.backends.vgg7 import vgg7_bn\n",
    "from only_train_once import OTO\n",
    "import torch\n",
    "\n",
    "model = vgg7_bn()\n",
    "model = model_to_quantize_model(model, quant_mode=QuantizationMode.WEIGHT_AND_ACTIVATION)\n",
    "dummy_input = torch.rand(1, 3, 32, 32)\n",
    "oto = OTO(model=model.cuda(), dummy_input=dummy_input.cuda())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01639056-422d-4bfb-89db-ff9f0725e807",
   "metadata": {},
   "source": [
    "#### (Optional) Visualize the pruning dependancy graph of DNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3e8cefb1-85cf-4833-a6ff-ee2f9270f02d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "(process:58696): Pango-WARNING **: 00:02:52.052: couldn't load font \"Times Not-Rotated 10\", falling back to \"Sans Not-Rotated 10\", expect ugly output.\n"
     ]
    }
   ],
   "source": [
    "# A ResNet_zig.gv.pdf will be generated to display the depandancy graph.\n",
    "oto.visualize(view=False, out_dir='../cache')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc99fc48-fed7-41a5-ab6d-f2e5686f2003",
   "metadata": {},
   "source": [
    "### Step 2. Dataset Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "57ec145d-4847-4f4b-8c12-782beb61cc61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to cifar10\\cifar-10-python.tar.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 170M/170M [00:22<00:00, 7.63MB/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting cifar10\\cifar-10-python.tar.gz to cifar10\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "from torchvision.datasets import CIFAR10\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "trainset = CIFAR10(root='cifar10', train=True, download=True, transform=transforms.Compose([\n",
    "            transforms.RandomHorizontalFlip(),\n",
    "            transforms.RandomCrop(32, 4),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])]))\n",
    "testset = CIFAR10(root='cifar10', train=False, download=True, transform=transforms.Compose([\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])]))\n",
    "\n",
    "trainloader =  torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True, num_workers=4)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=64, shuffle=False, num_workers=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65233349-da36-47bc-9af8-41a3f2d4429a",
   "metadata": {},
   "source": [
    "### Step 3. Setup the optimizer\n",
    "\n",
    "The following main hyperparameters need to be taken care.\n",
    "\n",
    "- `variant`: The optimizer that is used for training the baseline full model. Currently support `sgd`, `adam` and `adamw`.\n",
    "- `lr`: The initial learning rate.\n",
    "- `weight_decay`: Weight decay as standard DNN optimization.\n",
    "- `target_group_sparsity`: The target group sparsity, typically higher group sparsity refers to more FLOPs and model size reduction, meanwhile may regress model performance more.\n",
    "- `start_projection_step`: The number of steps that **starts** to do bit width projection.\n",
    "- `projection_steps`: The number of steps that **finishes** bit width projection (reach target bit width) after `start_projection_steps`.\n",
    "- `projection_periods`: Incrementally produce the group sparsity equally among projection periods.\n",
    "- `start_pruning_step`: The number of steps that **starts** to prune.\n",
    "- `pruning_steps`: The number of steps that **finishes** pruning (reach `target_group_sparsity`) after `start_pruning_steps`.\n",
    "- `pruning_periods`:  Incrementally produce the group sparsity equally among pruning periods.\n",
    "- `bit reduction`: the reduction of `max_bit` after the end of each projection period.\n",
    "- [`min_bit`,`max_bit`]: Initial bit width interval. The `max_bit` will reduce by `bit_reduction` after each projection period.\n",
    "\n",
    "<!-- We empirically suggest `start_pruning_steps` as 1/10 of total number of training steps. `pruning_steps` until 1/4 or 1/5 of total number of training steps.\n",
    "The advatnages of HESSO compared to DHSPG is its explicit control over group sparsity exploration, which is typically more convenient. -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "48af4116-bb7e-4156-bc3d-c32c8fc6f2c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-14 00:04:23,632 - GETA - INFO - Setup GETA\n",
      "2025-05-14 00:04:23,633 - GETA - INFO - importance_score_criteria: {'magnitude': 0.2, 'avg_magnitude': 0.2, 'cosine_similarity': 0.2, 'taylor_first_order': 0.2, 'taylor_second_order': 0.2}\n",
      "2025-05-14 00:04:23,633 - GETA - INFO - start_projection_step: 0\n",
      "2025-05-14 00:04:23,633 - GETA - INFO - projection_steps: 7820\n",
      "2025-05-14 00:04:23,634 - GETA - INFO - projection_periods: 5\n",
      "2025-05-14 00:04:23,634 - GETA - INFO - start_pruning_step: 7820\n",
      "2025-05-14 00:04:23,634 - GETA - INFO - pruning_steps: 7820\n",
      "2025-05-14 00:04:23,634 - GETA - INFO - pruning_periods: 5\n",
      "2025-05-14 00:04:23,635 - GETA - INFO - pruning_period_duration: 1564\n",
      "2025-05-14 00:04:23,635 - GETA - INFO - Target redundant groups per period: [281, 281, 281, 281, 284]\n"
     ]
    }
   ],
   "source": [
    "optimizer = oto.geta(\n",
    "    variant=\"adam\",\n",
    "    lr=1e-3,\n",
    "    lr_quant=1e-3,\n",
    "    first_momentum=0.9,\n",
    "    weight_decay=1e-4,\n",
    "    target_group_sparsity=0.5,\n",
    "    start_projection_step=0 * len(trainloader),\n",
    "    projection_periods=5,\n",
    "    projection_steps=10 * len(trainloader),\n",
    "    start_pruning_step=10 * len(trainloader),\n",
    "    pruning_periods=5,\n",
    "    pruning_steps=10 * len(trainloader),\n",
    "    bit_reduction=2,\n",
    "    min_bit_wt=4,\n",
    "    max_bit_wt=16,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3632cb7e-e1ae-460c-b415-81c158c80a20",
   "metadata": {},
   "source": [
    "### Step 4. Train VGG7 as normal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed9d98a1-a77b-4cc6-9acd-a1483c17e370",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\xiaoy\\miniconda3\\envs\\qhesso\\Lib\\site-packages\\torch\\optim\\lr_scheduler.py:224: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep: 0, loss: 1.31, norm_all:4367.90, grp_sparsity: 0.00, acc1: 63.1900, norm_import: 4367.90, norm_redund: 0.00, num_grp_import: 2816, num_grp_redund: 0\n",
      "Ep: 1, loss: 0.85, norm_all:4292.01, grp_sparsity: 0.00, acc1: 70.6700, norm_import: 4292.01, norm_redund: 0.00, num_grp_import: 2816, num_grp_redund: 0\n",
      "Ep: 2, loss: 0.69, norm_all:4240.82, grp_sparsity: 0.00, acc1: 71.9800, norm_import: 4240.82, norm_redund: 0.00, num_grp_import: 2816, num_grp_redund: 0\n",
      "Ep: 3, loss: 0.61, norm_all:4246.43, grp_sparsity: 0.00, acc1: 73.5600, norm_import: 4246.43, norm_redund: 0.00, num_grp_import: 2816, num_grp_redund: 0\n",
      "Ep: 4, loss: 0.55, norm_all:4331.38, grp_sparsity: 0.00, acc1: 77.9700, norm_import: 4331.38, norm_redund: 0.00, num_grp_import: 2816, num_grp_redund: 0\n"
     ]
    }
   ],
   "source": [
    "from tutorials.utils.utils import check_accuracy\n",
    "\n",
    "max_epoch = 50\n",
    "model.cuda()\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "# Every 50 epochs, decay lr by 10.0\n",
    "lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=50, gamma=0.1) \n",
    "\n",
    "for epoch in range(max_epoch):\n",
    "    f_avg_val = 0.0\n",
    "    model.train()\n",
    "    lr_scheduler.step()\n",
    "    for X, y in trainloader:\n",
    "        X = X.cuda()\n",
    "        y = y.cuda()\n",
    "        y_pred = model.forward(X)\n",
    "        f = criterion(y_pred, y)\n",
    "        optimizer.zero_grad()\n",
    "        f.backward()\n",
    "        f_avg_val += f\n",
    "        optimizer.step()\n",
    "    opt_metrics = optimizer.compute_metrics()\n",
    "    accuracy1, accuracy5 = check_accuracy(model, testloader)\n",
    "    f_avg_val = f_avg_val.cpu().item() / len(trainloader)\n",
    "    \n",
    "    print(\"Ep: {ep}, loss: {f:.2f}, norm_all:{param_norm:.2f}, grp_sparsity: {gs:.2f}, acc1: {acc1:.4f}, norm_import: {norm_import:.2f}, norm_redund: {norm_redund:.2f}, num_grp_import: {num_grps_import}, num_grp_redund: {num_grps_redund}\"\\\n",
    "         .format(ep=epoch, f=f_avg_val, param_norm=opt_metrics.norm_params, gs=opt_metrics.group_sparsity, acc1=accuracy1,\\\n",
    "         norm_import=opt_metrics.norm_important_groups, norm_redund=opt_metrics.norm_redundant_groups, \\\n",
    "         num_grps_import=opt_metrics.num_important_groups, num_grps_redund=opt_metrics.num_redundant_groups\n",
    "        ))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb8dabf9-04cf-4d55-89e4-a17c96d17cec",
   "metadata": {},
   "source": [
    "### Step 5. Get compressed model in torch format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f46e6b6e-6286-4f57-816f-f94f6ce5c40b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\xiaoy\\AppData\\Local\\Temp\\ipykernel_28528\\2333613023.py:7: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  compressed_model = torch.load(oto.compressed_model_path)\n",
      "c:\\Users\\xiaoy\\OneDrive\\Desktop\\Github Projects\\GETA\\geta\\tutorials\\..\\only_train_once\\quantization\\quant_layers.py:334: TracerWarning: torch.tensor results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.\n",
      "  weight_clip_val = torch.tensor(self.weight_clip_val, device=weight.device)\n",
      "c:\\Users\\xiaoy\\OneDrive\\Desktop\\Github Projects\\GETA\\geta\\tutorials\\..\\only_train_once\\quantization\\quant_layers.py:335: TracerWarning: torch.tensor results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.\n",
      "  q_s = torch.tensor(0.0, device=weight.device)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OTO graph constructor\n",
      "graph build\n",
      "NodePattern mul None\n",
      "NodePattern transpose None\n",
      "NodePattern matmul None\n",
      "Post-processing of graph completed.\n",
      "Graph has 28 nodes and 27 edges.\n"
     ]
    }
   ],
   "source": [
    "# By default OTO will construct subnet by the last checkpoint. If intermedia ckpt reaches the best performance,\n",
    "# need to reinitialize OTO instance\n",
    "# oto = OTO(torch.load(ckpt_path), dummy_input)\n",
    "# then construct subnetwork\n",
    "dummy_input = torch.rand(1, 3, 32, 32)\n",
    "oto.construct_subnet(out_dir='./cache')\n",
    "compressed_model = torch.load(oto.compressed_model_path)\n",
    "oto_compressed = OTO(compressed_model, dummy_input.cuda())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da9cd3b6-1db9-473d-9585-27e08c669265",
   "metadata": {},
   "source": [
    "### (Optional) Check the compressed model size\n",
    "- MACs: Multiply and accumulations\n",
    "- BOPs: Bit of operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dc731c99-3155-472e-9462-65ed8c9bf4d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full MACs for VGG7: 608.04855 M MACs\n",
      "Full BOPs for VGG7: 189709.46387199996 M BOPs\n",
      "Compressed MACs for VGG7: 608.04855 M MACs\n",
      "Compressed BOPs for VGG7: 189709.463872 M BOPs\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Get full model MACs, BOPs\n",
    "full_macs = oto.compute_macs(in_million=True, layerwise=True)\n",
    "full_bops = oto.compute_bops(in_million=True, layerwise=True)\n",
    "full_num_params = oto.compute_num_params(in_million=True)\n",
    "\n",
    "# Get compressed model MACs, BOPs\n",
    "compressed_macs = oto_compressed.compute_macs(in_million=True, layerwise=True)\n",
    "compressed_bops = oto_compressed.compute_bops(in_million=True, layerwise=True)\n",
    "\n",
    "print(f\"Full MACs for VGG7: {full_macs['total']} M MACs\")\n",
    "print(f\"Full BOPs for VGG7: {full_bops['total']} M BOPs\")\n",
    "print(f\"Compressed MACs for VGG7: {compressed_macs['total']} M MACs\")\n",
    "print(f\"Compressed BOPs for VGG7: {compressed_bops['total']} M BOPs\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "qhesso",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
